{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(csv_path, save_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(f'./{save_name}.parquet')\n",
    "    del df\n",
    "    gc.collect()\n",
    "    print(save_name, 'Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Done.\n",
      "test Done.\n"
     ]
    }
   ],
   "source": [
    "csv_to_parquet('./train.csv', 'train')\n",
    "csv_to_parquet('./test.csv', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.utils import parsedate\n",
    "\n",
    "\n",
    "train = pd.read_parquet('./train.parquet')\n",
    "test = pd.read_parquet('./test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>base_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>base_hour</th>\n",
       "      <th>road_in_use</th>\n",
       "      <th>lane_count</th>\n",
       "      <th>road_rating</th>\n",
       "      <th>road_name</th>\n",
       "      <th>multi_linked</th>\n",
       "      <th>connect_code</th>\n",
       "      <th>...</th>\n",
       "      <th>road_type</th>\n",
       "      <th>start_node_name</th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>start_longitude</th>\n",
       "      <th>start_turn_restricted</th>\n",
       "      <th>end_node_name</th>\n",
       "      <th>end_latitude</th>\n",
       "      <th>end_longitude</th>\n",
       "      <th>end_turn_restricted</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000000</td>\n",
       "      <td>20220623</td>\n",
       "      <td>목</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>지방도1112호선</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>제3교래교</td>\n",
       "      <td>33.427747</td>\n",
       "      <td>126.662612</td>\n",
       "      <td>없음</td>\n",
       "      <td>제3교래교</td>\n",
       "      <td>33.427749</td>\n",
       "      <td>126.662335</td>\n",
       "      <td>없음</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0000001</td>\n",
       "      <td>20220728</td>\n",
       "      <td>목</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>일반국도11호선</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>광양사거리</td>\n",
       "      <td>33.500730</td>\n",
       "      <td>126.529107</td>\n",
       "      <td>있음</td>\n",
       "      <td>KAL사거리</td>\n",
       "      <td>33.504811</td>\n",
       "      <td>126.526240</td>\n",
       "      <td>없음</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0000002</td>\n",
       "      <td>20211010</td>\n",
       "      <td>일</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>일반국도16호선</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>창고천교</td>\n",
       "      <td>33.279145</td>\n",
       "      <td>126.368598</td>\n",
       "      <td>없음</td>\n",
       "      <td>상창육교</td>\n",
       "      <td>33.280072</td>\n",
       "      <td>126.362147</td>\n",
       "      <td>없음</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0000003</td>\n",
       "      <td>20220311</td>\n",
       "      <td>금</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>태평로</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>남양리조트</td>\n",
       "      <td>33.246081</td>\n",
       "      <td>126.567204</td>\n",
       "      <td>없음</td>\n",
       "      <td>서현주택</td>\n",
       "      <td>33.245565</td>\n",
       "      <td>126.566228</td>\n",
       "      <td>없음</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0000004</td>\n",
       "      <td>20211005</td>\n",
       "      <td>화</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>일반국도12호선</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>애월샷시</td>\n",
       "      <td>33.462214</td>\n",
       "      <td>126.326551</td>\n",
       "      <td>없음</td>\n",
       "      <td>애월입구</td>\n",
       "      <td>33.462677</td>\n",
       "      <td>126.330152</td>\n",
       "      <td>없음</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  base_date day_of_week  base_hour  road_in_use  lane_count  \\\n",
       "0  TRAIN_0000000   20220623           목         17            0           1   \n",
       "1  TRAIN_0000001   20220728           목         21            0           2   \n",
       "2  TRAIN_0000002   20211010           일          7            0           2   \n",
       "3  TRAIN_0000003   20220311           금         13            0           2   \n",
       "4  TRAIN_0000004   20211005           화          8            0           2   \n",
       "\n",
       "   road_rating  road_name  multi_linked  connect_code  ...  road_type  \\\n",
       "0          106  지방도1112호선             0             0  ...          3   \n",
       "1          103   일반국도11호선             0             0  ...          0   \n",
       "2          103   일반국도16호선             0             0  ...          0   \n",
       "3          107        태평로             0             0  ...          0   \n",
       "4          103   일반국도12호선             0             0  ...          0   \n",
       "\n",
       "   start_node_name  start_latitude  start_longitude  start_turn_restricted  \\\n",
       "0            제3교래교       33.427747       126.662612                     없음   \n",
       "1            광양사거리       33.500730       126.529107                     있음   \n",
       "2             창고천교       33.279145       126.368598                     없음   \n",
       "3            남양리조트       33.246081       126.567204                     없음   \n",
       "4             애월샷시       33.462214       126.326551                     없음   \n",
       "\n",
       "  end_node_name  end_latitude  end_longitude end_turn_restricted target  \n",
       "0         제3교래교     33.427749     126.662335                  없음   52.0  \n",
       "1        KAL사거리     33.504811     126.526240                  없음   30.0  \n",
       "2          상창육교     33.280072     126.362147                  없음   61.0  \n",
       "3          서현주택     33.245565     126.566228                  없음   20.0  \n",
       "4          애월입구     33.462677     126.330152                  없음   38.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_col = ['day_of_week','start_turn_restricted','end_turn_restricted']\n",
    "for i in str_col:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(train[i])\n",
    "    train[i]=le.transform(train[i])\n",
    "    \n",
    "    for label in np.unique(test[i]):\n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test[i]=le.transform(test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4701217, 17)\n",
      "(4701217,)\n",
      "(291241, 17)\n"
     ]
    }
   ],
   "source": [
    "y_train = train['target'] \n",
    "\n",
    "X_train = train.drop(['id','base_date', 'target','road_name', 'start_node_name', 'end_node_name','vehicle_restricted'], axis=1)\n",
    "\n",
    "test = test.drop(['id','base_date', 'road_name', 'start_node_name', 'end_node_name','vehicle_restricted'], axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def time_window(df, t, t_sep):\n",
    "    seq_len = t\n",
    "    seqence_length = seq_len + t_sep\n",
    "\n",
    "    result = []\n",
    "    for index in tqdm(range(len(df) - seqence_length)):\n",
    "        result.append(df[index: index + seqence_length])\n",
    "\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3760972/3760972 [00:01<00:00, 2009068.05it/s]\n",
      "100%|██████████| 940243/940243 [00:00<00:00, 1992039.74it/s]\n",
      "100%|██████████| 3760972/3760972 [01:58<00:00, 31671.73it/s]\n",
      "100%|██████████| 940243/940243 [00:22<00:00, 42125.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# train\n",
    "# train, validation 분리 (8 : 2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, random_state=119)\n",
    "\n",
    "# scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# time series window 생성\n",
    "X_train = time_window(X_train_scaled, 0, 1)\n",
    "X_val = time_window(X_val_scaled, 0, 1)\n",
    "y_train = time_window(y_train, 0, 1)\n",
    "y_val = time_window(y_val, 0, 1)\n",
    "\n",
    "# y의 길이와 같은 길이로 설정\n",
    "X_train = X_train[:len(y_train)]\n",
    "X_val = X_val[:len(y_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "\n",
    "# 시드고정\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout):\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(inputs) # 레이어 정규화\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=activation)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=activation)(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## earlystop patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def call_back_set(name, epoch, batch_size):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=earlystop_patience)\n",
    "\n",
    "    if os.path.exists(f'./check') == False:\n",
    "        os.mkdir(f'./check')\n",
    "\n",
    "    filename = f'./check/{name}-{epoch}-{batch_size}.h5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filename,\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True,\n",
    "                                 mode='auto'\n",
    "                                 )\n",
    "    return [early_stopping, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train, x_val, y_val, name, epoch, batch_size, learning_rate, verbose = 1):\n",
    "\n",
    "\n",
    "    model = build_model(\n",
    "    x_train.shape[1:],\n",
    "    head_size=head_size,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_transformer_blocks=num_transformer_blocks,\n",
    "    mlp_units=mlp_units,\n",
    "    mlp_dropout=mlp_dropout,\n",
    "    dropout=dropout,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history1 = model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs = epoch,\n",
    "            steps_per_epoch=len(x_train) / batch_size,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(x_val, y_val),\n",
    "            validation_steps=len(x_val) / batch_size,\n",
    "            shuffle=False,\n",
    "            callbacks=call_back_set(name, epoch, batch_size),\n",
    "            verbose=verbose)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "\n",
    "epsilon = 1e-6\n",
    "epoch = 100 # 400~500\n",
    "batch = 2048 # 10\n",
    "learning_rate = 0.03 # lr 늘려도 될 것 같음\n",
    "head_size = 256\n",
    "num_heads = 4\n",
    "ff_dim = 4\n",
    "num_transformer_blocks = 4\n",
    "mlp_units = [64]\n",
    "mlp_dropout = 0.1\n",
    "dropout = 0.1\n",
    "activation = 'swish'\n",
    "earlystop_patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1836/1836 [==============================] - 100s 49ms/step - loss: 134.6431 - val_loss: 88.1462\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 88.14616, saving model to ./check\\transformer-end_turn_restricted-100-2048.h5\n",
      "Epoch 2/100\n",
      "1836/1836 [==============================] - 88s 48ms/step - loss: 100.8083 - val_loss: 84.1279\n",
      "\n",
      "Epoch 00002: val_loss improved from 88.14616 to 84.12787, saving model to ./check\\transformer-end_turn_restricted-100-2048.h5\n",
      "Epoch 3/100\n",
      "1836/1836 [==============================] - 88s 48ms/step - loss: 97.0826 - val_loss: 81.5202\n",
      "\n",
      "Epoch 00003: val_loss improved from 84.12787 to 81.52022, saving model to ./check\\transformer-end_turn_restricted-100-2048.h5\n",
      "Epoch 4/100\n",
      "1836/1836 [==============================] - 89s 48ms/step - loss: 94.4057 - val_loss: 78.8916\n",
      "\n",
      "Epoch 00004: val_loss improved from 81.52022 to 78.89157, saving model to ./check\\transformer-end_turn_restricted-100-2048.h5\n",
      "Epoch 5/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 93.1760 - val_loss: 77.5522\n",
      "\n",
      "Epoch 00005: val_loss improved from 78.89157 to 77.55217, saving model to ./check\\transformer-end_turn_restricted-100-2048.h5\n",
      "Epoch 6/100\n",
      "1836/1836 [==============================] - 92s 50ms/step - loss: 92.4670 - val_loss: 77.8056\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 77.55217\n",
      "Epoch 7/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 91.5519 - val_loss: 78.0385\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 77.55217\n",
      "Epoch 8/100\n",
      "1836/1836 [==============================] - 90s 49ms/step - loss: 90.8455 - val_loss: 80.9657\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 77.55217\n",
      "Epoch 9/100\n",
      "1836/1836 [==============================] - 91s 50ms/step - loss: 90.3254 - val_loss: 77.6994\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 77.55217\n",
      "Epoch 10/100\n",
      "1836/1836 [==============================] - 90s 49ms/step - loss: 90.0242 - val_loss: 75.5127\n",
      "\n",
      "Epoch 00010: val_loss improved from 77.55217 to 75.51271, saving model to ./check\\transformer-end_turn_restricted-100-2048.h5\n",
      "Epoch 11/100\n",
      "1836/1836 [==============================] - 89s 49ms/step - loss: 89.7010 - val_loss: 77.1184\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 75.51271\n",
      "Epoch 12/100\n",
      "1836/1836 [==============================] - 91s 50ms/step - loss: 6469.1187 - val_loss: 252.1701\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 75.51271\n",
      "Epoch 13/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 253.8218 - val_loss: 249.7706\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 75.51271\n",
      "Epoch 14/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 249.7953 - val_loss: 238.8920\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 75.51271\n",
      "Epoch 15/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 228.1504 - val_loss: 183.0583\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 75.51271\n",
      "Epoch 16/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 252.0880 - val_loss: 254.3692\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 75.51271\n",
      "Epoch 17/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 254.5900 - val_loss: 254.3692\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 75.51271\n",
      "Epoch 18/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 254.5922 - val_loss: 254.3692\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 75.51271\n",
      "Epoch 19/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 254.5937 - val_loss: 254.3693\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 75.51271\n",
      "Epoch 20/100\n",
      "1836/1836 [==============================] - 91s 49ms/step - loss: 254.5939 - val_loss: 254.3692\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 75.51271\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>24.791613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>45.600868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>56.051453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>28.270933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>39.804962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291236</th>\n",
       "      <td>TEST_291236</td>\n",
       "      <td>47.185257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291237</th>\n",
       "      <td>TEST_291237</td>\n",
       "      <td>51.513466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291238</th>\n",
       "      <td>TEST_291238</td>\n",
       "      <td>21.670900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291239</th>\n",
       "      <td>TEST_291239</td>\n",
       "      <td>27.392941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291240</th>\n",
       "      <td>TEST_291240</td>\n",
       "      <td>39.928562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     target\n",
       "0       TEST_000000  24.791613\n",
       "1       TEST_000001  45.600868\n",
       "2       TEST_000002  56.051453\n",
       "3       TEST_000003  28.270933\n",
       "4       TEST_000004  39.804962\n",
       "...             ...        ...\n",
       "291236  TEST_291236  47.185257\n",
       "291237  TEST_291237  51.513466\n",
       "291238  TEST_291238  21.670900\n",
       "291239  TEST_291239  27.392941\n",
       "291240  TEST_291240  39.928562\n",
       "\n",
       "[291241 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# transformer 모델 훈련\n",
    "transformer = train(X_train, y_train, X_val, y_val, f'transformer-{i}', epoch,\n",
    "                    batch, learning_rate)\n",
    "transformer.load_weights(f'./check/transformer-{i}-{epoch}-{batch}.h5')\n",
    "\n",
    "if os.path.exists(f'./model') == False:\n",
    "    os.mkdir(f'./model')\n",
    "\n",
    "# 모델 저장\n",
    "transformer.save(f'./model/transformer-{i}-{epoch}-{batch}.h5')\n",
    "\n",
    "\n",
    "# test\n",
    "# scaling\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "# reshape\n",
    "test = test_scaled.reshape(test_scaled.shape[0], 1, test_scaled.shape[1])\n",
    "\n",
    "# predict\n",
    "model_test = tf.keras.models.load_model(f'./model/transformer-{i}-{epoch}-{batch}.h5')\n",
    "pred = model_test.predict(test)\n",
    "\n",
    "# 결과 저장\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission.to_csv(\"./submit.csv\", index = False)\n",
    "\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deeplearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b4c3ec0e12fd879c7a79621ce69efc8e5dffb38beade75d33d8e63cc2d1166b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
