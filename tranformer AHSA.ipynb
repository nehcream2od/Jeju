{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sherpa\n",
    "import sherpa.algorithms.bayesian_optimization as bayesian_optimization\n",
    "import tempfile\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(csv_path, save_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(f'./{save_name}.parquet')\n",
    "    del df\n",
    "    gc.collect()\n",
    "    print(save_name, 'Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Done.\n",
      "test Done.\n"
     ]
    }
   ],
   "source": [
    "csv_to_parquet('./train.csv', 'train')\n",
    "csv_to_parquet('./test.csv', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.utils import parsedate\n",
    "\n",
    "\n",
    "train = pd.read_parquet('./train.parquet')\n",
    "test = pd.read_parquet('./test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>base_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>base_hour</th>\n",
       "      <th>road_in_use</th>\n",
       "      <th>lane_count</th>\n",
       "      <th>road_rating</th>\n",
       "      <th>road_name</th>\n",
       "      <th>multi_linked</th>\n",
       "      <th>connect_code</th>\n",
       "      <th>...</th>\n",
       "      <th>road_type</th>\n",
       "      <th>start_node_name</th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>start_longitude</th>\n",
       "      <th>start_turn_restricted</th>\n",
       "      <th>end_node_name</th>\n",
       "      <th>end_latitude</th>\n",
       "      <th>end_longitude</th>\n",
       "      <th>end_turn_restricted</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000000</td>\n",
       "      <td>20220623</td>\n",
       "      <td>목</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>지방도1112호선</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>제3교래교</td>\n",
       "      <td>33.427747</td>\n",
       "      <td>126.662612</td>\n",
       "      <td>없음</td>\n",
       "      <td>제3교래교</td>\n",
       "      <td>33.427749</td>\n",
       "      <td>126.662335</td>\n",
       "      <td>없음</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0000001</td>\n",
       "      <td>20220728</td>\n",
       "      <td>목</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>일반국도11호선</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>광양사거리</td>\n",
       "      <td>33.500730</td>\n",
       "      <td>126.529107</td>\n",
       "      <td>있음</td>\n",
       "      <td>KAL사거리</td>\n",
       "      <td>33.504811</td>\n",
       "      <td>126.526240</td>\n",
       "      <td>없음</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0000002</td>\n",
       "      <td>20211010</td>\n",
       "      <td>일</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>일반국도16호선</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>창고천교</td>\n",
       "      <td>33.279145</td>\n",
       "      <td>126.368598</td>\n",
       "      <td>없음</td>\n",
       "      <td>상창육교</td>\n",
       "      <td>33.280072</td>\n",
       "      <td>126.362147</td>\n",
       "      <td>없음</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0000003</td>\n",
       "      <td>20220311</td>\n",
       "      <td>금</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>태평로</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>남양리조트</td>\n",
       "      <td>33.246081</td>\n",
       "      <td>126.567204</td>\n",
       "      <td>없음</td>\n",
       "      <td>서현주택</td>\n",
       "      <td>33.245565</td>\n",
       "      <td>126.566228</td>\n",
       "      <td>없음</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0000004</td>\n",
       "      <td>20211005</td>\n",
       "      <td>화</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>일반국도12호선</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>애월샷시</td>\n",
       "      <td>33.462214</td>\n",
       "      <td>126.326551</td>\n",
       "      <td>없음</td>\n",
       "      <td>애월입구</td>\n",
       "      <td>33.462677</td>\n",
       "      <td>126.330152</td>\n",
       "      <td>없음</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  base_date day_of_week  base_hour  road_in_use  lane_count  \\\n",
       "0  TRAIN_0000000   20220623           목         17            0           1   \n",
       "1  TRAIN_0000001   20220728           목         21            0           2   \n",
       "2  TRAIN_0000002   20211010           일          7            0           2   \n",
       "3  TRAIN_0000003   20220311           금         13            0           2   \n",
       "4  TRAIN_0000004   20211005           화          8            0           2   \n",
       "\n",
       "   road_rating  road_name  multi_linked  connect_code  ...  road_type  \\\n",
       "0          106  지방도1112호선             0             0  ...          3   \n",
       "1          103   일반국도11호선             0             0  ...          0   \n",
       "2          103   일반국도16호선             0             0  ...          0   \n",
       "3          107        태평로             0             0  ...          0   \n",
       "4          103   일반국도12호선             0             0  ...          0   \n",
       "\n",
       "   start_node_name  start_latitude  start_longitude  start_turn_restricted  \\\n",
       "0            제3교래교       33.427747       126.662612                     없음   \n",
       "1            광양사거리       33.500730       126.529107                     있음   \n",
       "2             창고천교       33.279145       126.368598                     없음   \n",
       "3            남양리조트       33.246081       126.567204                     없음   \n",
       "4             애월샷시       33.462214       126.326551                     없음   \n",
       "\n",
       "  end_node_name  end_latitude  end_longitude end_turn_restricted target  \n",
       "0         제3교래교     33.427749     126.662335                  없음   52.0  \n",
       "1        KAL사거리     33.504811     126.526240                  없음   30.0  \n",
       "2          상창육교     33.280072     126.362147                  없음   61.0  \n",
       "3          서현주택     33.245565     126.566228                  없음   20.0  \n",
       "4          애월입구     33.462677     126.330152                  없음   38.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_col = ['day_of_week','start_turn_restricted','end_turn_restricted']\n",
    "for i in str_col:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(train[i])\n",
    "    train[i]=le.transform(train[i])\n",
    "    \n",
    "    for label in np.unique(test[i]):\n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test[i]=le.transform(test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4701217, 17)\n",
      "(4701217,)\n",
      "(291241, 17)\n"
     ]
    }
   ],
   "source": [
    "y_train = train['target'] \n",
    "\n",
    "X_train = train.drop(['id','base_date', 'target','road_name', 'start_node_name', 'end_node_name','vehicle_restricted'], axis=1)\n",
    "\n",
    "test = test.drop(['id','base_date', 'road_name', 'start_node_name', 'end_node_name','vehicle_restricted'], axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def time_window(df, t, t_sep):\n",
    "    seq_len = t\n",
    "    seqence_length = seq_len + t_sep\n",
    "\n",
    "    result = []\n",
    "    for index in tqdm(range(len(df) - seqence_length)):\n",
    "        result.append(df[index: index + seqence_length])\n",
    "\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3760972/3760972 [00:01<00:00, 2081353.85it/s]\n",
      "100%|██████████| 940243/940243 [00:00<00:00, 2017729.79it/s]\n",
      "100%|██████████| 3760972/3760972 [02:02<00:00, 30578.38it/s]\n",
      "100%|██████████| 940243/940243 [00:27<00:00, 34246.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# train\n",
    "# train, validation 분리 (8 : 2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, random_state=119)\n",
    "\n",
    "# scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# time series window 생성\n",
    "X_train = time_window(X_train_scaled, 0, 1)\n",
    "X_val = time_window(X_val_scaled, 0, 1)\n",
    "y_train = time_window(y_train, 0, 1)\n",
    "y_val = time_window(y_val, 0, 1)\n",
    "\n",
    "# y의 길이와 같은 길이로 설정\n",
    "X_train = X_train[:len(y_train)]\n",
    "X_val = X_val[:len(y_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "\n",
    "# 시드고정\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout):\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(inputs) # 레이어 정규화\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=activation)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=activation)(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sherpa Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "\n",
    "epsilon = 1e-6\n",
    "mlp_units = [64]\n",
    "mlp_dropout = 0.1\n",
    "dropout = 0.1\n",
    "earlystop_patience = 10\n",
    "\n",
    "parameters = [sherpa.Continuous('learning_rate', [1e-4, 1e-2], 'log'),\n",
    "              sherpa.Choice('batch', [64, 128, 256, 512, 1024]),\n",
    "              sherpa.Discrete('num_transformer_blocks', [2, 16]),\n",
    "              sherpa.Discrete('ff_dim', [2, 16]),\n",
    "              sherpa.Choice('head_size', [32, 64, 128, 256]),\n",
    "              sherpa.Discrete('num_heads', [2, 16]),              \n",
    "              sherpa.Choice('activation', ['relu', 'swish'])]\n",
    "algorithm = alg = sherpa.algorithms.SuccessiveHalving(r=1, R=9, eta=3, s=0, max_finished_configs=1)\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=algorithm,\n",
    "                     lower_is_better=False,\n",
    "                     disable_dashboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t1\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.0031064565916570303, 'batch': 1024, 'num_transformer_blocks': 15, 'ff_dim': 12, 'head_size': 256, 'num_heads': 7, 'activation': 'relu', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '1'}\n",
      "\n",
      "Creating new model for trial 1...\n",
      "\n",
      "3672/3672 [==============================] - 361s 94ms/step - loss: 120.7703 - val_loss: 76.5539\n",
      "MAE loss:  6.71792338698902\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 450). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t2\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.0004610553724347624, 'batch': 128, 'num_transformer_blocks': 10, 'ff_dim': 8, 'head_size': 128, 'num_heads': 9, 'activation': 'swish', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '2'}\n",
      "\n",
      "Creating new model for trial 2...\n",
      "\n",
      "29382/29382 [==============================] - 1267s 43ms/step - loss: 111.0012 - val_loss: 83.2945\n",
      "MAE loss:  6.960507845091085\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 300). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t3\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.005555620885158486, 'batch': 256, 'num_transformer_blocks': 14, 'ff_dim': 14, 'head_size': 128, 'num_heads': 3, 'activation': 'swish', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '3'}\n",
      "\n",
      "Creating new model for trial 3...\n",
      "\n",
      "14691/14691 [==============================] - 864s 58ms/step - loss: 96.3006 - val_loss: 65.0628\n",
      "MAE loss:  6.129128399810737\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t4\n",
      "Epochs:\t1 to 4\n",
      "Parameters:{'learning_rate': 0.005555620885158486, 'batch': 256, 'num_transformer_blocks': 14, 'ff_dim': 14, 'head_size': 128, 'num_heads': 3, 'activation': 'swish', 'save_to': '4', 'resource': 3, 'rung': 1, 'load_from': '3'}\n",
      "\n",
      "Loading model from:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\3 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_conv1d_62_layer_call_and_return_conditional_losses_257615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_4_layer_call_and_return_conditional_losses_258884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_54_layer_call_and_return_conditional_losses_270295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_66_layer_call_and_return_conditional_losses_272041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_58_layer_call_and_return_conditional_losses_270877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_76_layer_call_and_return_conditional_losses_258826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_4_layer_call_and_return_conditional_losses_273594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_74_layer_call_and_return_conditional_losses_258653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_70_layer_call_and_return_conditional_losses_258307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_52_layer_call_and_return_conditional_losses_270004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_56_layer_call_and_return_conditional_losses_270586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_2_layer_call_and_return_conditional_losses_268560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_72_layer_call_and_return_conditional_losses_272914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_56_layer_call_and_return_conditional_losses_257096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_60_layer_call_and_return_conditional_losses_271168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_58_layer_call_and_return_conditional_losses_257269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_50_layer_call_and_return_conditional_losses_269713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_74_layer_call_and_return_conditional_losses_273205) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_70_layer_call_and_return_conditional_losses_272623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_2_layer_call_and_return_conditional_losses_266862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_64_layer_call_and_return_conditional_losses_257788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_76_layer_call_and_return_conditional_losses_273496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_60_layer_call_and_return_conditional_losses_257442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_72_layer_call_and_return_conditional_losses_258480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_64_layer_call_and_return_conditional_losses_271750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_66_layer_call_and_return_conditional_losses_257961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_54_layer_call_and_return_conditional_losses_256923) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_68_layer_call_and_return_conditional_losses_258134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_62_layer_call_and_return_conditional_losses_271459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_52_layer_call_and_return_conditional_losses_256750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_68_layer_call_and_return_conditional_losses_272332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_256408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_50_layer_call_and_return_conditional_losses_256577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "14691/14691 [==============================] - 826s 55ms/step - loss: 75.9467 - val_loss: 61.2724\n",
      "MAE loss:  5.941279230634241\n",
      "Epoch 3/3\n",
      "14691/14691 [==============================] - 817s 56ms/step - loss: 72.8604 - val_loss: 57.5855\n",
      "MAE loss:  5.779961556693815\n",
      "Epoch 4/4\n",
      "14691/14691 [==============================] - 820s 56ms/step - loss: 70.7303 - val_loss: 57.5268\n",
      "MAE loss:  5.8057123333255305\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t5\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.0030459022368485356, 'batch': 512, 'num_transformer_blocks': 2, 'ff_dim': 14, 'head_size': 256, 'num_heads': 3, 'activation': 'swish', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '5'}\n",
      "\n",
      "Creating new model for trial 5...\n",
      "\n",
      "7345/7345 [==============================] - 81s 11ms/step - loss: 142.1039 - val_loss: 96.4312\n",
      "MAE loss:  7.741712847250476\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t6\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.0003181616306611627, 'batch': 128, 'num_transformer_blocks': 9, 'ff_dim': 7, 'head_size': 256, 'num_heads': 15, 'activation': 'relu', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '6'}\n",
      "\n",
      "Creating new model for trial 6...\n",
      "\n",
      "29382/29382 [==============================] - 1183s 40ms/step - loss: 121.6821 - val_loss: 82.5392\n",
      "MAE loss:  6.98564167288894\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 270). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t7\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.0024089375621135873, 'batch': 1024, 'num_transformer_blocks': 13, 'ff_dim': 13, 'head_size': 64, 'num_heads': 3, 'activation': 'relu', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '7'}\n",
      "\n",
      "Creating new model for trial 7...\n",
      "\n",
      "3672/3672 [==============================] - 216s 56ms/step - loss: 118.4170 - val_loss: 72.3412\n",
      "MAE loss:  6.497158513491242\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 390). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t8\n",
      "Epochs:\t1 to 4\n",
      "Parameters:{'learning_rate': 0.0024089375621135873, 'batch': 1024, 'num_transformer_blocks': 13, 'ff_dim': 13, 'head_size': 64, 'num_heads': 3, 'activation': 'relu', 'save_to': '8', 'resource': 3, 'rung': 1, 'load_from': '7'}\n",
      "\n",
      "Loading model from:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\7 ...\n",
      "\n",
      "Epoch 2/2\n",
      "3672/3672 [==============================] - 227s 59ms/step - loss: 88.7736 - val_loss: 66.9060\n",
      "MAE loss:  6.2421968218324135\n",
      "Epoch 3/3\n",
      "3672/3672 [==============================] - 215s 58ms/step - loss: 83.4844 - val_loss: 65.1702\n",
      "MAE loss:  6.138065667525829\n",
      "Epoch 4/4\n",
      "3672/3672 [==============================] - 214s 58ms/step - loss: 79.3321 - val_loss: 61.3620\n",
      "MAE loss:  6.001417224086274\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 390). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t9\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.0002762039976376295, 'batch': 64, 'num_transformer_blocks': 13, 'ff_dim': 4, 'head_size': 128, 'num_heads': 13, 'activation': 'relu', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '9'}\n",
      "\n",
      "Creating new model for trial 9...\n",
      "\n",
      "58765/58765 [==============================] - 2969s 50ms/step - loss: 116.1644 - val_loss: 83.5391\n",
      "MAE loss:  7.097218982612798\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 390). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t10\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.0002767327634802866, 'batch': 1024, 'num_transformer_blocks': 2, 'ff_dim': 3, 'head_size': 32, 'num_heads': 8, 'activation': 'swish', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '10'}\n",
      "\n",
      "Creating new model for trial 10...\n",
      "\n",
      "3672/3672 [==============================] - 47s 12ms/step - loss: 271.6072 - val_loss: 157.9987\n",
      "MAE loss:  10.246973569540495\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t11\n",
      "Epochs:\t0 to 1\n",
      "Parameters:{'learning_rate': 0.0003259048442058629, 'batch': 512, 'num_transformer_blocks': 2, 'ff_dim': 11, 'head_size': 256, 'num_heads': 7, 'activation': 'swish', 'resource': 1, 'rung': 0, 'load_from': '', 'save_to': '11'}\n",
      "\n",
      "Creating new model for trial 11...\n",
      "\n",
      "7345/7345 [==============================] - 99s 13ms/step - loss: 185.0564 - val_loss: 112.6330\n",
      "MAE loss:  8.384994529963663\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t12\n",
      "Epochs:\t1 to 4\n",
      "Parameters:{'learning_rate': 0.0031064565916570303, 'batch': 1024, 'num_transformer_blocks': 15, 'ff_dim': 12, 'head_size': 256, 'num_heads': 7, 'activation': 'relu', 'save_to': '12', 'resource': 3, 'rung': 1, 'load_from': '1'}\n",
      "\n",
      "Loading model from:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\1 ...\n",
      "\n",
      "Epoch 2/2\n",
      "7345/7345 [==============================] - 616s 82ms/step - loss: 89.6410 - val_loss: 68.5074\n",
      "MAE loss:  6.29123868331996\n",
      "Epoch 3/3\n",
      "7345/7345 [==============================] - 602s 82ms/step - loss: 81.1023 - val_loss: 62.9588\n",
      "MAE loss:  6.0847129206288955\n",
      "Epoch 4/4\n",
      "7345/7345 [==============================] - 601s 82ms/step - loss: 76.7320 - val_loss: 60.3973\n",
      "MAE loss:  5.961845276088969\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 450). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\12\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Trial:\t13\n",
      "Epochs:\t4 to 13\n",
      "Parameters:{'learning_rate': 0.005555620885158486, 'batch': 256, 'num_transformer_blocks': 14, 'ff_dim': 14, 'head_size': 128, 'num_heads': 3, 'activation': 'swish', 'save_to': '13', 'resource': 9, 'rung': 2, 'load_from': '4'}\n",
      "\n",
      "Loading model from:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\4 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_conv1d_50_layer_call_and_return_conditional_losses_485131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_50_layer_call_and_return_conditional_losses_471995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_2_layer_call_and_return_conditional_losses_482280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_72_layer_call_and_return_conditional_losses_488332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_60_layer_call_and_return_conditional_losses_472860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_54_layer_call_and_return_conditional_losses_485713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_68_layer_call_and_return_conditional_losses_487750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_52_layer_call_and_return_conditional_losses_485422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_56_layer_call_and_return_conditional_losses_472514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_74_layer_call_and_return_conditional_losses_474071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_70_layer_call_and_return_conditional_losses_488041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_62_layer_call_and_return_conditional_losses_486877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_2_layer_call_and_return_conditional_losses_483978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_58_layer_call_and_return_conditional_losses_486295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_72_layer_call_and_return_conditional_losses_473898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_76_layer_call_and_return_conditional_losses_488914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_66_layer_call_and_return_conditional_losses_473379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_471826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_64_layer_call_and_return_conditional_losses_487168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_4_layer_call_and_return_conditional_losses_489012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_4_layer_call_and_return_conditional_losses_474302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_66_layer_call_and_return_conditional_losses_487459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_70_layer_call_and_return_conditional_losses_473725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_54_layer_call_and_return_conditional_losses_472341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_56_layer_call_and_return_conditional_losses_486004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_62_layer_call_and_return_conditional_losses_473033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_52_layer_call_and_return_conditional_losses_472168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_64_layer_call_and_return_conditional_losses_473206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_68_layer_call_and_return_conditional_losses_473552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_60_layer_call_and_return_conditional_losses_486586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_76_layer_call_and_return_conditional_losses_474244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_58_layer_call_and_return_conditional_losses_472687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_74_layer_call_and_return_conditional_losses_488623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "7345/7345 [==============================] - 464s 62ms/step - loss: 67.0530 - val_loss: 53.0344\n",
      "MAE loss:  5.549729315793271\n",
      "Epoch 6/6\n",
      "7345/7345 [==============================] - 454s 62ms/step - loss: 65.4455 - val_loss: 51.5380\n",
      "MAE loss:  5.436175295636936\n",
      "Epoch 7/7\n",
      "7345/7345 [==============================] - 452s 62ms/step - loss: 64.2926 - val_loss: 50.4228\n",
      "MAE loss:  5.350047987986291\n",
      "Epoch 8/8\n",
      "7345/7345 [==============================] - 460s 63ms/step - loss: 63.3956 - val_loss: 50.2030\n",
      "MAE loss:  5.369793487335861\n",
      "Epoch 9/9\n",
      "7345/7345 [==============================] - 464s 63ms/step - loss: 62.7970 - val_loss: 49.8527\n",
      "MAE loss:  5.3723092691653775\n",
      "Epoch 10/10\n",
      "7345/7345 [==============================] - 466s 63ms/step - loss: 62.2707 - val_loss: 49.2138\n",
      "MAE loss:  5.292538710417435\n",
      "Epoch 11/11\n",
      "7345/7345 [==============================] - 465s 63ms/step - loss: 61.7151 - val_loss: 48.7439\n",
      "MAE loss:  5.259261885582947\n",
      "Epoch 12/12\n",
      "7345/7345 [==============================] - 469s 64ms/step - loss: 61.2984 - val_loss: 49.0999\n",
      "MAE loss:  5.235974853668758\n",
      "Epoch 13/13\n",
      "7345/7345 [==============================] - 472s 64ms/step - loss: 61.0097 - val_loss: 49.1897\n",
      "MAE loss:  5.249115452772651\n",
      "Saving model at:  C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\nehcr\\AppData\\Local\\Temp\\tmpyzm0zve0\\13\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "for trial in study:\n",
    "    # Getting number of training epochs\n",
    "    initial_epoch = {1: 0, 3: 1, 9: 4}[trial.parameters['resource']]\n",
    "    epochs = trial.parameters['resource'] + initial_epoch\n",
    "\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Trial:\\t{trial.id}\\nEpochs:\\t{initial_epoch} to {epochs}\\nParameters:{trial.parameters}\\n\")\n",
    "\n",
    "    if trial.parameters['load_from'] == \"\":\n",
    "        print(f\"Creating new model for trial {trial.id}...\\n\")\n",
    "\n",
    "        # Get hyperparameters\n",
    "        learning_rate = trial.parameters['learning_rate']\n",
    "        batch_size = trial.parameters['batch']\n",
    "        activation = trial.parameters['activation']\n",
    "        num_transformer_blocks = trial.parameters['num_transformer_blocks']\n",
    "        ff_dim = trial.parameters['ff_dim']\n",
    "        head_size = trial.parameters['head_size']\n",
    "        num_heads = trial.parameters['num_heads']\n",
    "\n",
    "        # Create model\n",
    "        model = build_model(X_train.shape[1:],\n",
    "                            head_size=head_size,\n",
    "                            num_heads=num_heads,\n",
    "                            ff_dim=ff_dim,\n",
    "                            num_transformer_blocks=num_transformer_blocks,\n",
    "                            mlp_units=mlp_units,\n",
    "                            mlp_dropout=mlp_dropout,\n",
    "                            dropout=dropout,\n",
    "                            )\n",
    "\n",
    "        model.compile(loss=\"mean_squared_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "        \n",
    "    else:\n",
    "        print(f\"Loading model from: \", os.path.join(model_dir, trial.parameters['load_from']), \"...\\n\")\n",
    "\n",
    "        # Loading model\n",
    "        model = tf.keras.models.load_model(os.path.join(model_dir, trial.parameters['load_from']))\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    for i in range(initial_epoch, epochs):\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            model.fit(\n",
    "        X_train, y_train,\n",
    "        initial_epoch=i,\n",
    "        epochs = i+1,\n",
    "        steps_per_epoch=len(X_train) / batch_size,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        validation_steps=len(X_val) / batch_size,\n",
    "        shuffle=True)\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "        print(\"MAE loss: \", mae)\n",
    "        study.add_observation(trial=trial, iteration=i,\n",
    "                              objective=-mae,\n",
    "                              context={'loss': mae})\n",
    "        \n",
    "\n",
    "    study.finalize(trial=trial)\n",
    "    print(f\"Saving model at: \", os.path.join(model_dir, trial.parameters['save_to']))\n",
    "    model.save(os.path.join(model_dir, trial.parameters['save_to']))\n",
    "\n",
    "    study.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trial-ID': 13,\n",
       " 'Iteration': 11,\n",
       " 'activation': 'swish',\n",
       " 'batch': 256,\n",
       " 'ff_dim': 14,\n",
       " 'head_size': 128,\n",
       " 'learning_rate': 0.005555620885158486,\n",
       " 'load_from': '4',\n",
       " 'num_heads': 3,\n",
       " 'num_transformer_blocks': 14,\n",
       " 'resource': 9,\n",
       " 'rung': 2,\n",
       " 'save_to': '13',\n",
       " 'Objective': -5.235974853668758,\n",
       " 'loss': 5.235974853668758}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.get_best_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# scaling\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "# reshape\n",
    "test = test_scaled.reshape(test_scaled.shape[0], 1, test_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_conv1d_70_layer_call_and_return_conditional_losses_1724109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_52_layer_call_and_return_conditional_losses_1721490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_66_layer_call_and_return_conditional_losses_1709447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_76_layer_call_and_return_conditional_losses_1724982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_74_layer_call_and_return_conditional_losses_1724691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_2_layer_call_and_return_conditional_losses_1720046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_62_layer_call_and_return_conditional_losses_1722945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_58_layer_call_and_return_conditional_losses_1722363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_56_layer_call_and_return_conditional_losses_1708582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_66_layer_call_and_return_conditional_losses_1723527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_72_layer_call_and_return_conditional_losses_1724400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_56_layer_call_and_return_conditional_losses_1722072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_4_layer_call_and_return_conditional_losses_1725080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_2_layer_call_and_return_conditional_losses_1718348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_76_layer_call_and_return_conditional_losses_1710312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_58_layer_call_and_return_conditional_losses_1708755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_68_layer_call_and_return_conditional_losses_1709620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_60_layer_call_and_return_conditional_losses_1708928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1707894) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_62_layer_call_and_return_conditional_losses_1709101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_64_layer_call_and_return_conditional_losses_1709274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_50_layer_call_and_return_conditional_losses_1708063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_4_layer_call_and_return_conditional_losses_1710370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_72_layer_call_and_return_conditional_losses_1709966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_60_layer_call_and_return_conditional_losses_1722654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_64_layer_call_and_return_conditional_losses_1723236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_70_layer_call_and_return_conditional_losses_1709793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_52_layer_call_and_return_conditional_losses_1708236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_54_layer_call_and_return_conditional_losses_1708409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_54_layer_call_and_return_conditional_losses_1721781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_74_layer_call_and_return_conditional_losses_1710139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_50_layer_call_and_return_conditional_losses_1721199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_conv1d_68_layer_call_and_return_conditional_losses_1723818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>29.396742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>43.523006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>60.596142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>32.455292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>42.918282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291236</th>\n",
       "      <td>TEST_291236</td>\n",
       "      <td>49.485130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291237</th>\n",
       "      <td>TEST_291237</td>\n",
       "      <td>53.355247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291238</th>\n",
       "      <td>TEST_291238</td>\n",
       "      <td>24.626883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291239</th>\n",
       "      <td>TEST_291239</td>\n",
       "      <td>25.863487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291240</th>\n",
       "      <td>TEST_291240</td>\n",
       "      <td>35.261589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     target\n",
       "0       TEST_000000  29.396742\n",
       "1       TEST_000001  43.523006\n",
       "2       TEST_000002  60.596142\n",
       "3       TEST_000003  32.455292\n",
       "4       TEST_000004  42.918282\n",
       "...             ...        ...\n",
       "291236  TEST_291236  49.485130\n",
       "291237  TEST_291237  53.355247\n",
       "291238  TEST_291238  24.626883\n",
       "291239  TEST_291239  25.863487\n",
       "291240  TEST_291240  35.261589\n",
       "\n",
       "[291241 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "model_test = tf.keras.models.load_model(os.path.join(model_dir, trial.parameters['save_to']))\n",
    "pred = model_test.predict(test)\n",
    "\n",
    "# 결과 저장\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission.to_csv(\"./submit.csv\", index = False)\n",
    "\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pycaret')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1deac5ab06a2859c650586b052102da9ba46a8fd722b1a38e714dc58e67e4ae5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
